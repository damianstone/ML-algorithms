-*- Features (independent variable)

The features are the column with which you're going to predict the dependent variable

-*- Dependent variable vector

The import or the result column: for example, the dataset would be the "purchased"
because we're looking to predict if some future customers are going to purchase 
a certain product based on these information

Usually in the last column of the dataset

-*- Handling missing data

For example if we have a salary column and one row doesn't have a salary, then one way
to handle this missing data is to assing it the average of all salaries 

-*- Enconding categorical variable
One-hot encoding -> represent categorical variables in binary so we don't any order number problems

-*- Splitting the dataset into training and test set
Think of this like a practice exam. You study (train) using a portion of the questions (training set) 
and then you evaluate your knowledge using new questions you haven't seen before (test set). 
This helps verify your understanding and preparation for the real exam

-*- Feature scaling 
Imagine measuring your height in meters and your weight in grams. They're on completely different scales, right? 
If we want to compare or combine these two, it'd be easier if they were on a similar scale, like meters and kilograms. 
That's what feature scaling does - it makes sure all your data is on a similar scale, making it easier for 
your machine learning model to process and learn from

Two types: Standardisation, Normalisation
Always use the standardisation